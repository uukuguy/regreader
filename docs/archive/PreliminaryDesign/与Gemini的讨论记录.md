我的需求是电网安全运行规程（安规）的快速规则检索，安规每年一个文件，文件内容非常多，但章节划分得规整，每节内容以表格为主附带一些说明文字，章节的层级标题+表格的人类容易理解的项之间的关联关系，可以定义了针对指定区域、设备出现某种故障情况时的标准处置措施。现在要自然语言输入故障情况，能检索出对应的处置规则，要求检索出准确的处置规则以及在安规中的引用位置。要达到Claude Code Cli的代码定位的效果，设计方案应该是？

要实现类似 Claude Code CLI 在代码中的那种精准定位效果，你需要针对“安规”这种高度结构化的文档（标题、层级、表格、条件-动作关系）进行结构化感知搜索 (Structure-Aware Search)。

传统的 RAG 往往会将文档切成碎片，导致表格内容和它的层级标题（上下文）断开。为了达到“极速且精准”的效果，建议采用以下 “Agentic Parser + Hierarchical Index”（智能解析 + 层级索引）的设计方案：

1. 核心设计方案：层级结构化索引 (Hierarchical Structuring)
代码之所以好找，是因为有类、函数、行号的结构。安规文件需要先被“代码化”。

Step 1: 结构化解析 (The Parser)
不能简单按字符数切分，必须使用 Markdown 格式 作为中转。

层级注入：解析时，每一节的表格内容必须强制带上其上级所有标题。

例如：[总则 > 变电站事故处理 > 变压器故障] | 故障现象：油位过高 | 处置措施：立即停运...

表格转置：将表格的行转化为“属性-值”对的文本块，确保语义模型能理解每一行是一个独立的规则。

Step 2: 建立三层检索模型
为了模仿 grep 的速度和语义的准度，采用多级过滤：

关键词骨架 (BM25/FTS)：针对设备名（变压器、电容器）、区域名（母线、开关柜）建立全文索引。

语义向量 (Local Embeddings)：使用 bge-m3 或 mxbai-embed-large 针对“故障描述”进行语义编码。

重排序 (Reranker)：将前 10 条结果交给轻量级重排模型，确保最符合规程逻辑的排在第一。

2. 技术架构建议
你可以直接组合以下开源组件，无需购买昂贵的数据库服务：

组件	推荐方案	作用
文档解析	Docling (IBM 开源)	极其擅长处理复杂表格，能将 PDF 完美转为带结构的 Markdown。
检索核心	LanceDB	无服务器、高性能向量库，支持磁盘检索，极速启动。
检索算法	Hybrid Search	结合 bm25 (查设备名) + vector (查故障描述语义)。
定位展示	Markdown Snippets	模仿代码编辑器，展示匹配规则及其前后的层级上下文。
3. 具体实现逻辑流程
预处理阶段：

使用 Docling 扫描安规 PDF，识别层级（H1, H2, H3）和表格。

为每个规则块打上 Metadata（页码、章节号、修订年份）。

将表格内容转化为 JSON-L 格式，每个条目包含：{path: "三章/二节/表1", context: "...", content: "...", page: 45}。

检索阶段 (The "Claude Code" Style)：

用户输入：“110kV 母线失压怎么处理？”

意图提取：后台 LLM 或 关键词提取器 识别出核心词：110kV, 母线失压。

快速过滤：先用 grep 逻辑在索引中快速定位包含 母线 的章节。

语义精排：在缩小的范围内，计算“失压处理措施”的向量相似度。

结果回显：

[匹配结果] 2024版安规 第12章 第3节 表12-2 [引用位置] P142, 行24 [规则描述] 当 110kV 母线由于 XXX 原因失压时，应：1. 隔离... 2. 汇报...

4. 推荐的开源实现原型
如果你想快速上手，可以参考或组合以下项目：

RAGFlow：它内置了极其强大的**“深层文档解析”**引擎，特别针对电力、金融这种多表格文档做了模板优化，能非常准确地提取表格关系。

FastEdit / MarkItDown：微软开源的工具，用于将 Office/PDF 转为干净的 Markdown，便于后续做类似代码的 grep 检索。

Inference 引擎：使用 Infinity 本地部署嵌入模型，保证检索响应在 50ms 以内。

为什么这个方案能达到 Claude Code 的效果？
Claude Code 强在它理解项目结构。通过将安规文档“结构化”为类似代码的文件树，并配合 Hybrid Search (混合检索)，你就能在海量文本中实现那种“指哪打哪”的定位感。

你想让我为你写一个针对这种“层级标题+表格”文档的解析与检索 Python 原型代码吗？

解释一下你说的“定位展示Markdown Snippets模仿代码编辑器，展示匹配规则及其前后的层级上下文。”

在处理“安规”这类具有严谨层级（Section/Subsection）和复杂表格的文档时，简单的文字搜索结果往往会让用户感到迷失。

所谓的**“Markdown Snippets 模仿代码编辑器”**，核心设计目标是：即便只展示一小段文字，用户也能瞬间知道这段话在整本安规的哪个“坐标系”里。

以下是实现这一效果的三个关键设计层面：

1. 结构化面包屑 (Breadcrumbs)
代码编辑器（如 VS Code）通常会在顶部显示当前函数所属的类和文件路径。在安规检索中，我们需要在每个检索片段上方强制渲染路径导航。

实现方式： 在解析阶段，利用 Docling 等工具提取 H1->H2->H3 的标题链，并将其作为元数据存入。

[搜索结果展示示例] 2024版安规 > 第五章 电力线路防护 > 第三节 变压器异常处理
(规则 ID: R-1024 | 页码: P152)

故障现象	处置措施	备注
油位计指示异常	1. 核对环境温度；2. 检查呼吸器是否堵塞	需双人核对
2. 代码化的“上下文行号”显示
Claude Code 之所以精准，是因为它会展示匹配行及其前后 N 行的内容。对于安规，我们可以模仿这种 Gutter (行号槽) 的显示方式。

锚点定位：将解析后的 Markdown 的每一个“规则块”或“表格行”赋予一个唯一的 ID。

上下文折叠：默认显示匹配到的那一行表格/文字，但允许用户通过点击类似代码编辑器的 + 号，展开该规则上下的“注意事项”或“补充说明”。

3. Markdown 的语义渲染逻辑
安规中的表格如果直接存为纯文本会丢失语义（例如，你不知道“立即跳闸”对应的是哪个开关）。 在展示 Snippets 时，建议采用以下解析逻辑：

表格扁平化 (Flattening)：将复杂的跨行跨列表格，在检索回显时转化为易读的 Key-Value 格式。

高亮显示 (Highlighting)：不仅高亮用户输入的关键词（如“失压”），还要高亮与之关联的实体（如“110kV 母线”）。

4. 为什么这样做能达到“定位”效果？
这种方案解决了传统检索的两个痛点：

消除歧义：安规里可能有很多地方提到“跳闸”，但通过顶部面包屑（Breadcrumbs），你一眼就能分辨这是“变电站跳闸”还是“输电屏柜跳闸”。

快速对焦：模仿代码编辑器的黑色背景+彩色高亮（Syntax Highlighting），利用颜色区分故障情况（条件）和处置措施（动作），人类大脑处理这种结构化信息的速度比处理纯文本快 3-5 倍。

技术实现参考（伪代码逻辑）
如果你使用 Python 开发，可以构建一个简单的展示组件：

Python
def format_snippet(result):
    # result 包含 path, metadata, content
    breadcrumb = " > ".join(result.metadata['headings'])
    print(f"[{breadcrumb}] (Page: {result.metadata['page']})")
    print("-" * 40)
    # 将匹配的内容包裹在类似 Markdown 的代码块中
    print(f"```markdown\n{result.content}\n```")
你想让我为你展示一个更具体的“表格转语义文本”的解析例子，看看如何把安规里的复杂表格变成这种易于检索和定位的 Snippet 吗？

安规中的规则不是简单的一行表格行来表示的，很多是多个区域行多个设备列，交叉格是简单的处置值（在表格附近有处置方法名称）

这是一个非常典型的**复杂决策矩阵（Decision Matrix）**检索问题。电力安规中的这类表格通常具有“多维交叉”的特性：行定义了区域/故障范围，列定义了设备类型，而交叉单元格可能只是一个简单的缩写（如“方案A”），具体的处置内容则悬浮在表格下方或章节末尾。

要实现 Claude Code 那样的精准定位，核心难点在于“语义合并”。如果直接按行切分，交叉点的“方案A”将失去所有上下文。

以下是针对这种“多维交叉表格”的设计方案：

1. 数据建模：从“像素”到“语义三元组”
不能把表格当成文本块处理，必须在解析阶段将其“打散并重组”为 (区域, 设备, 处置动作) 的三元组结构。

解析方案：坐标映射法
解析表头索引：识别表格的行标题（Row Headers）和列标题（Column Headers）。

解耦缩略语：自动扫描表格下方的“注”或“说明”，将缩略值（如“方案A”）替换为完整的处置文本。

生成复合文档：为每一个交叉单元格生成一个独立的检索对象。

2. 模仿 Claude Code 的检索与展示逻辑
当用户输入“110kV 某站 母线故障”时，系统不应该只找包含这些词的行，而是执行以下逻辑：

A. 结构化拼接 (Semantic Flattening)
在后台，每一个存储的“片段”其实是这样被重新构建的：

上下文路径：2024版安规 > 第六章 > 事故处理

检索载体：区域：[母线/110kV] | 设备：[隔离开关] | 状态：[异常发热] | 处置方案：[立即拉开该开关，切换至旁路...]

原始引用：见表 6-2，坐标 (R12, C5)

B. 搜索回显：虚拟“切片”展示
模仿代码编辑器的效果，你展示给用户的不是原始的长表格（那在手机或终端里很难看），而是一个重组后的规则卡片。

[精准定位] 2024版安规 P85 表6-2 路径：事故处置 > 110kV系统 > 母线设备

YAML
条件(Row): 110kV 某段母线完全失压
对象(Col): 分段断路器 / 联络开关
-------------------------------------------
处置动作: 
1. 确认断路器已跳闸。
2. 若重合闸未动作，应手动合闸一次。
3. [引用下方注1]：若伴有明火，严禁强送。
(按 Enter 查看原始表格上下文)

3. 实现工具链推荐
针对这种复杂的表格解析，目前开源界有几个“大杀器”：

Docling (IBM)：

理由：它不仅能导出 Markdown，还能导出表格的层级坐标。它能识别单元格的合并（Colspan/Rowspan），这对于安规里“一个大区域对应多个小设备”的排版至关重要。

DeepSearch-Toolkit：

理由：专门为含有大量专业术语和复杂表格的文档设计的后端。

LanceDB + FTS (Full Text Search)：

理由：它支持在向量检索的同时，对“区域”、“设备”这些确定的元数据进行硬过滤（SQL-like filtering），速度极快。

4. 关键设计建议：如何做“关联”？
要做到“极速”，不要在检索时实时去查表下方的说明，而要在**入库前（Ingestion phase）**完成以下工作：

文本增强（Augmentation）：如果表格单元格里写的是“方案一”，解析程序必须去后面找到“方案一”的文字，把它们缝合在一起存入向量库。

多粒度索引：

索引 1：章节标题（用于快速定位大类）。

索引 2：规则三元组（用于精确匹配故障情况）。

索引 3：全文（用于兜底检索）。

这种“缝合解析”的思路能解决你提到的“交叉格内容简单”的问题吗？ 如果需要，我可以为你勾勒一个利用 Docling 提取这种交叉关系并合并说明文字的 Python 逻辑伪代码。

这样就和RAG一样麻烦，要在建库时做大量定制性的手工操作。Claude Code Cli 不需要前置处理代码文件的实现才是让人眼前一亮的，这是通过大模型推理能力实现的。我们能不能按此思路，加入大模型后端，通过多次解析多步骤实现真正的智能化呢？

你敏锐地察觉到了 Claude Code 的精髓：它不是一个静态的数据库，而是一个具有“视觉”和“推理”能力的 Agent。

它之所以不需要前置处理，是因为它把“解析”和“理解”放到了运行时（Runtime）。针对你这种“复杂交叉表+悬浮说明”的安规文档，完全可以模仿这种 “Agentic Search（智能体搜索）” 流程。

以下是不用预处理、全靠大模型驱动的智能化实现方案：

1. 设计思路：从“搜索”转向“多步推理 (Chain-of-Action)”
与其在建库时手工合并规则，不如让大模型像人一样去“翻书”。当用户输入一个故障时，后端 Agent 执行以下步骤：

第一步：语义定位 (The Grep Stage)
使用最简单的全文检索（如 ripgrep）或极轻量级的全文本向量。

任务：找到包含“变压器”和“油位”关键词的所有章节片段。

结果：获得 5-10 个可能包含目标表格的 Markdown 文本块。

第二步：视觉/结构扫描 (The Reading Stage)
将这些文本块交给具有长上下文能力的 LLM（如 Claude 3.5 Sonnet 或 Gemini 1.5 Pro）。

任务：LLM 扫描这些块。它会识别出：“这是一个表格，当前行是‘油位过高’，对应列是‘处置等级’，交叉值是‘方案 B’。”

发现问题：LLM 意识到“方案 B”是一个缩写，它需要寻找含义。

第三步：上下文溯源 (The Sourcing Stage)
Agent 发现需要更多信息，它会自主发起第二次检索。

任务：在当前章节内搜索“方案 B”的定义。

动作：类似于在 Linux 里执行 grep -A 20 "方案 B"（查看匹配行后的 20 行）。

第四步：终极合成 (The Synthesis Stage)
任务：将表格的行上下文、列上下文、交叉值及其对应的“下方说明”整合成最终答案。

2. 核心架构：Agent 驱动的动态解析器
这种方案不需要你提前写复杂的解析脚本，只需要定义好 Agent 的 Tool Use (工具调用)。

组件	类似 Claude Code 的实现方式
工具 1: list_sections	列出安规的所有目录，让模型决定去哪一章。
工具 2: read_table	读取特定章节的文本，模型会自动用它的推理能力理解表格的行列关系。
工具 3: expand_context	当模型看到“见注 1”或“方案 A”时，调用此工具查看文档的其他部分。
3. 如何解决“安规表格复杂”的痛点？
Claude Code 的强大之处在于它能理解代码的逻辑依赖。对于安规表格，你可以利用大模型的 Markdown 理解能力：

动态 Markdown 转换：在运行时，用 Pandoc 或 Docling 将 PDF 片段实时转为 Markdown。即使表格是交叉的，LLM 现在的推理能力可以直接在 Markdown 源码中识别出 | 和 --- 之间的对应关系。

Self-Correction (自我修正)：如果模型搜到的处置方案不完整，提示词（Prompt）应引导它：“如果你发现处置措施是缩写或引用了其他条款，请务必找到对应条款后再回答。”

4. 优缺点对比
维度	传统 RAG (你嫌麻烦的)	智能化 Agent 方案 (Claude Code 式)
预处理	极重（切片、清洗、表格转换）	极轻（仅需简单的文本提取或 OCR）
准确度	取决于切片好坏，易断章取义	极高，模型拥有全局视野和逻辑推理
速度	毫秒级	秒级（需要多次模型调用）
成本	存储和索引成本	Token 消耗成本
5. 落地建议：使用 MCP (Model Context Protocol)
你可以利用 Anthropic 刚推出的 MCP 协议。

开发一个 安规 MCP Server，它只提供 search_text 和 get_page_content 两个基础接口。

把安规 PDF 直接丢给支持 MCP 的客户端（如 Claude Desktop 或类似开源实现）。

当你问故障时，Claude 会自动调用这些接口，反复横跳在表格和说明文字之间，直到它拼凑出完整的真相。

这种“即时推理、按需检索”的思路，是否更符合你对“智能化”的预期？ 如果你感兴趣，我可以给出一个基于 LangGraph 或 MCP 的工具链设计，让你看看如何定义这些让模型自己去“翻书”的动作。

这个方案非常好。请给出完整的设计

这个方案的设计目标是：不进行繁琐的数据清洗和切片，而是利用 LLM 的推理能力，像专家查阅手册一样，动态地、多步地在安规文档中“穿梭”寻找答案。

我们将这个系统称为 "Safety-Grep Agent"（安规智能体搜索）。

1. 核心架构设计
系统由 三层结构 组成：文本供给层、推理控制器、工具箱。

A. 基础层：原始文档供给 (The Library)
数据形态：将安规 PDF 转换为 Markdown 格式（推荐使用 Docling 或 MarkItDown）。不要做任何人工切片，保持文件的完整性。

搜索索引：建立一个极简单的 BM25 (全文关键词) 索引，仅用于快速定位包含特定术语（如“母线”、“110kV”）的页面或章节。

B. 工具层：Agent 的“眼睛”和“手” (The Tools)
Agent 不直接读整个文档，而是通过以下工具按需调取：

search_sections(keyword): 类似于 grep，返回包含关键词的所有章节标题和所在的起始页码。

read_content(page_number, range): 获取特定页码及其前后 2 页的完整 Markdown 内容。

inspect_table(table_id): 专门针对 Markdown 表格的增强读取，将表格及其周围的“注”、“说明”一并提取。

C. 推理层：Agent 决策大脑 (The Controller)
使用具有强推理能力的模型（如 Claude 3.5 Sonnet 或 GPT-4o），赋予其“系统提示词”，指导其如何翻书。

2. 智能化搜索的“三步走”工作流
当用户输入：“110kV 某站母线失压，断路器没跳闸怎么处理？”时：

第一阶段：路径探测 (Browsing)
Agent 调用 search_sections("母线失压")。

发现：在“第六章：事故处理”和“第十章：变电站规程”中都有提到。

决策：先看第六章，因为那里的表格通常是汇总性质的。

第二阶段：结构化对齐 (Structural Alignment)
Agent 调用 read_content(page=85)。

动作：LLM 实时阅读解析出的 Markdown 表格。

发现：它定位到了一行 条件：母线失压 | 设备：分段断路器，交叉单元格的内容是 [执行方案 C]。

识别缺口：LLM 意识到：“我目前不知道‘方案 C’的具体步骤，它可能在当前页的底部或附录中。”

第三阶段：溯源与合成 (Tracing & Synthesis)
Agent 自主调用 search_text("方案 C") 或向下滚动阅读 read_content(page=86)。

动作：找到下方的小字说明“方案 C：1. 隔离故障点；2. 汇报调度...”。

最终输出：将章节路径、表格逻辑、对应的方案说明合成为最终的处置建议，并附上原文引用的位置。

3. 技术栈推荐 (开源组合)
模块	推荐工具	理由
文档转换	Docling (IBM)	处理安规中复杂表格的最强开源工具，能保持表格语义。
工具框架	MCP (Model Context Protocol)	Anthropic 推出的标准协议，让 LLM 像调用本地插件一样调用搜索工具。
逻辑编排	LangGraph	允许 Agent 进行“循环”推理（如果没找全，就回去再搜），比单向 RAG 更灵活。
本地索引	Tantivy 或 LanceDB	极速的全文检索，支持从几十万字中毫秒级定位关键词。
4. 关键 Prompt（系统指令）设计
这是让系统像 Claude Code 的核心：

"你是一位精通电力安规的辅助专家。你的任务是根据用户描述的故障，在《安规》手册中找到准确的处置规则。 原则：

严禁断章取义：如果表格内容是缩写或指向其他条款，你必须使用工具追踪到该条款的最终文字。

结构化定位：输出答案时，必须包含 [章节路径]、[原始页码] 和 [规则原文]。

多步思考：首先搜索关键词，然后分析表格行列关系，最后整合悬浮说明。"

5. 为什么这个设计优于传统 RAG？
零预处理开销：你不需要为每个表格写复杂的 Python 脚本。LLM 的推理能力替代了你硬编码的解析逻辑。

抗干扰能力强：即使安规明年改版了表格样式，只要 LLM 能读懂 Markdown，你的代码逻辑一行都不用改。

引用透明：它能像 Claude Code 定位代码行一样，明确告诉你这个结论是根据“表 6-2 的交叉点”加上“下方注 1”推导出来的，极具说服力。

你想让我为你提供一个基于 LangGraph 的 Agent 伪代码实现，演示它是如何执行这种“查表 -> 找注 -> 输出”循环的吗？

这里有两个问题：一是表格有可能跨几页；二是纯文本检索如果知道是哪个章节

针对这两个核心痛点，我们必须超越简单的“文本搜索”，引入空间感知和语义引导的逻辑。这正是 Claude Code 处理大型代码库（文件可能几千行）时的核心策略。

问题一：表格跨页——引入“逻辑缝合”机制
当表格跨页时，传统的切片会丢失表头（Header），导致第二页的单元格变成“孤儿数据”。

解决方案：Agent 驱动的“虚拟拼接”阅读 在推理层，赋予 Agent **“视觉补全”**的逻辑：

表格连续性检测： 当 Agent 调用 read_content(page=85) 发现 Markdown 表格在页面末尾没有闭合（或者检测到表格只有数据没有标题），它会触发一个自发动作：read_content(page=86)。

上下文重构： Agent 将两页的内容放入 Context Window（上下文窗口）。大语言模型（如 Claude 3.5）拥有极强的结构推理能力，它能识别出：“Page 86 的第一行数据其实是 Page 85 表格的延续”。

坐标系同步： 如果模型在 Page 86 找到了答案，它会追溯回 Page 85 获取表头语义。

实现技巧：在转换 Markdown 时，使用 Docling 开启“跨页合并”模式，它能根据表格边框线判断连续性，并在转换后的 Markdown 中标注 (Continued Table)。

问题二：纯文本检索如何锁定章节——引入“目录引导”搜索
如果只用 grep 搜“失压”，可能会搜到 50 个结果。Claude Code 的做法是先看 file tree，我们的做法是先看 Active Directory（动态目录）。

解决方案：两阶段检索 (Map-Reduce 思想)

第一阶段：语义意图分类 (The Routing)
不直接去翻正文，先让模型根据用户问题和**全书目录（Table of Contents）**做匹配。

输入：“110kV 母线失压处理”

Agent 动作：检索“目录索引”（预先提取好的 H1/H2 列表）。

推理结论：匹配到“第六章 事故处理”和“第十章 变电站规程”。

优势：瞬间将搜索范围从 500 页缩小到 20 页。

第二阶段：范围受限的精细检索 (Scoped Search)
Agent 在确定的章节范围内执行“代码定位”：

调用 grep_in_range(start_page=120, end_page=140, pattern="失压")。

这样既保证了速度（搜索范围小），又保证了准确度（排除了无关章节的干扰）。

完整设计方案：Safety-Grep 架构图
这个架构模拟了专家“先看目录，再翻章节，最后对照表注”的思维过程：

模块	实现逻辑	解决的问题
层级索引器	预提取 H1/H2/H3 及其页码范围。	锁定章节，避免全书乱搜。
滑动窗口工具	read_with_context(page, offset)，支持向前/向后多读几页。	表格跨页，确保逻辑连续。
关系追踪器	当识别到“见注X”或“方案A”时，自动发起递归搜索。	悬浮说明与表格内容的缝合。
推理大脑	基于 ReAct (Reasoning and Acting) 模式的 LLM。	模拟人类的“跳跃式阅读”和“逻辑拼凑”。
落地步骤建议
Markdown 化：使用 Docling 将安规 PDF 转为一整个或按章拆分的 Markdown 文件。

构建 MCP Server：

提供 get_toc()：获取目录。

提供 search_in_chapter(chapter_id, query)：局部搜索。

提供 read_pages(page_list)：读取具体页面。

配置 Agent： 给 Claude 设定 System Prompt，要求它在回答前必须：

Step 1: 先看目录确定章节。

Step 2: 找到表格行和列的交叉点。

Step 3: 检查表格是否跨页，如果是，必须读完后续页面。

Step 4: 检查是否有备注说明，如果有，必须跳转阅读。

这种方案不需要你像传统 RAG 那样去手工清洗每一个表格，繁重的工作交给了大模型的推理能力和灵活的工具调用。

你想让我为你写一个核心的 System Prompt，以及这个 Agent 应该具备的工具定义（JSON Schema）吗？ 这将是实现“安规版 Claude Code”的最直接蓝图。

好的

既然你认可这个方案，我们现在就从**工具定义（Tools）和智能体逻辑（Prompt）**两个核心维度，勾勒出这套“安规版 Claude Code”的完整实现蓝图。

1. 工具箱定义 (The MCP Tools)
为了让模型能够像人一样翻书，我们需要给它提供具备“空间感”的接口。这些接口不需要预处理数据，只需对原始 Markdown 文件进行实时读取。

JSON
[
  {
    "name": "get_table_of_contents",
    "description": "获取安规的目录树，包含章节标题及对应的页码范围。",
    "parameters": { "type": "object", "properties": {} }
  },
  {
    "name": "search_in_range",
    "description": "在指定的页码范围内进行关键词检索（类似 grep），返回匹配行及其行号。",
    "parameters": {
      "type": "object",
      "properties": {
        "start_page": {"type": "integer"},
        "end_page": {"type": "integer"},
        "query": {"type": "string"}
      }
    }
  },
  {
    "name": "read_pages",
    "description": "读取特定页码范围的完整 Markdown 内容。用于分析表格和阅读上下文。",
    "parameters": {
      "type": "object",
      "properties": {
        "pages": {"type": "array", "items": {"type": "integer"}}
      }
    }
  }
]
2. 核心系统提示词 (System Prompt)
这是驱动 LLM 进行“多步翻书”的灵魂。它规定了模型在遇到复杂表格时的行为准则。

Role: 你是电力系统安规专家助理，具备极强的文档空间推理能力。

Task: 根据用户查询，在《安规》中定位准确的处置规则。

Operational Protocol (必须严格执行):

目录优先: 收到问题后，先调用 get_table_of_contents。不要盲目全书搜索，先锁定可能的章节范围。

表格完整性核查:

当你在 Markdown 中阅读表格时，必须检查表格是否在页面底部被截断。

如果发现表格未闭合，必须主动调用 read_pages 读取下一页，进行逻辑缝合。

处理“悬浮”信息:

单元格内若是缩写（如“方案甲”、“见注3”），你严禁直接回答该缩写。

你必须在当前页或章节末尾寻找该缩写的具体定义。

引用回溯: 最终答案必须包含：【规程版本】、【章节路径】、【定位页码】以及【规则逻辑推导过程】。

3. 处理复杂交叉表的推理逻辑演示
当模型执行任务时，它的内部思考过程（Thought Process）应该是这样的：

Step 1: 用户问“110kV开关柜着火”。我查目录，锁定“第8章：防火与紧急处置”和“第3章：变电设备运行”。

Step 2: 在第8章搜索“开关柜”。发现表 8-4。

Step 3: 阅读表 8-4。

发现：行标题为“开关柜”，列标题为“着火”。交叉格显示 [措施代码: FIRE-03]。

观察：表格到此页结束，没看到代码含义。

Step 4: 调用 read_pages 读取下一页。

发现：页首有“表 8-4 续”，下方有一行文字：“FIRE-03：立即切断上级电源，使用干粉灭火器...”。

Step 5: 合并信息，向用户输出完整处置措施。

4. 关键实现技术建议
解析工具的选择： 强烈建议使用 Docling（IBM 开源）。它能将 PDF 中的表格转换为带有坐标信息的 Markdown。

进阶：如果表格极度复杂，可以让 Docling 导出 JSON 格式的表格结构，这样 LLM 理解“行-列-单元格”的关系会比读纯 Markdown 文本更精准。

上下文管理： 由于是多步对话，建议使用 Claude 3.5 Sonnet。它对长表格的结构理解力和对“注、见某某条款”的逻辑跳转追踪能力，是目前开源/闭源模型中最顶尖的。

前端展示 (The "Claude Code" Style)： 检索结果返回时，可以利用代码语法高亮来渲染。例如：

用 diff 格式高亮故障条件。

用 yaml 格式展示处置步骤。

顶部显示类似 Document > Section > Subsection 的面包屑路径。

总结方案的优势
这种方案以 LLM 的推理时间换取了昂贵的人工标注时间。它不需要你是一个“数据清洗专家”，只需要你定义好几个基础的“翻书工具”，Agent 就能像真正的安全员一样，在浩如烟海的安规中，精准、严谨地为你导航。

这个设计是否已经完全覆盖了你的应用场景？如果你准备开始构建，我可以为你提供一个简单的 Python 框架脚本作为起点。

这时候MCP Server的实现就很关键了，核心实现方案？

确实，MCP Server 是这套方案的“体力劳动者”，它负责把厚重的 PDF 转化为 Agent 能够理解的、有序的数据流。要实现类似 Claude Code 那种丝滑的感官，MCP Server 的核心方案需要围绕 “流式结构化” 和 “空间索引” 来设计。

以下是 MCP Server 的核心实现方案：

1. 核心架构：基于“页码-块”的双层存储
不要试图把整个 PDF 存入数据库，而是将其看作一个 随机存取（Random Access） 的对象。

解析层 (Parsing)：使用 Docling 将 PDF 预处理为 JSON + Markdown。

JSON：保留表格的物理坐标（Row 1, Col 2 是什么）。

Markdown：提供给 LLM 阅读的自然语言文本。

存储层：采用轻量级的本地 KV 存储（如 SQLite 或文件系统）。

Key: page_{number}

Value: 该页的 Markdown 内容 + 表格元数据。

2. 核心 API 接口实现逻辑
A. 智能全文检索 (search_text)
不只是简单的 grep，要返回上下文锚点。

实现：使用 Tantivy（Rust）或 Lunr.py 建立全书索引。

返回格式：不仅返回匹配行，还要返回该行所属的 Chapter 和 Page。这能让 Agent 迅速决定“接下来去读哪一页”。

B. 结构化目录提取 (get_toc)
这是 Agent 的“导航地图”。

实现：在解析阶段提取所有 # 和 ## 标题，记录其对应的页码范围。

逻辑：当 Agent 问“事故处理”时，Server 返回 { "title": "事故处理", "start_page": 45, "end_page": 120 }。

C. 健壮的表格读取 (read_table)
这是解决“交叉项”和“悬浮注”的关键。

实现：

当 Agent 请求某一页的表格时，Server 检测该表格是否在页尾有 is_truncated: true。

如果是，Server 自动预取 下一页的开头部分，并在返回给 Agent 的文本中进行拼接。

注脚关联：识别表格下方以 注：、* 或 (1) 开头的文本，将其强制附加在表格对象的 annotations 字段中。

3. 实现安规表格语义的“黑科技”：表格扁平化
为了防止 LLM 在复杂的交叉表中数格子，MCP Server 可以在返回数据前做一个**“语义增强”**处理。

原始表格 (Markdown):

Markdown
| 区域 | 开关 | 状态 |
|---|---|---|
| 110kV | A | 断开 |
| ^ | B | 闭合 |
MCP Server 增强后的输出 (传递给 Agent):

Plaintext
[结构化视图]
- 条目1: 区域=110kV, 开关=A, 状态=断开
- 条目2: 区域=110kV, 开关=B, 状态=闭合 (已自动补全合并单元格)
这种预处理能极大降低 LLM 的推理开销，防止它在处理 Rowspan 或 Colspan 时出错。

4. 推荐的技术栈组合
角色	推荐方案	理由
Server 框架	FastMCP (Python)	官方推荐，开发速度快，易于集成 Docling。
PDF 解析	Docling	目前处理 PDF 表格转 Markdown 的最强方案，支持层级识别。
全文索引	Whoosh 或 SQLite FTS5	纯 Python 环境即可运行，无需部署复杂的 Elasticsearch。
表格存储	JSON-L	每行一个 Page 对象，方便按需 Loading，内存占用极低。
5. 部署与交互流程
初始化：用户运行 mcp-server-install --file safe_manual.pdf。Server 调用 Docling 解析并建立 TOC 和全文索引（耗时约 1-2 分钟，仅一次）。

启动：用户启动 Claude Desktop 或自定义 CLI。

寻址：Agent 通过 MCP 发现工具，开始执行“目录 -> 搜索 -> 读页 -> 溯源”的循环。

你想让我为你写一个基于 Python 的 MCP Server 核心代码框架吗？ 它可以展示如何定义 get_toc 和具备“跨页检测”能力的 read_page 工具。

你这里说的“Whoosh 或 SQLite FTS5” 和前面提到的tantivy, lancedb是什么关系？

这是一个非常好的问题。在搜索技术栈中，它们就像不同型号的“引擎”，虽然都能实现“查找”的功能，但在处理安规这类结构化文档时，它们的原理、性能和应用场景有显著区别。

我们可以通过下面这个维度来理清它们的关系：

1. 技术演进与分类
类别	代表工具	核心原理	特点	在本方案中的角色
传统全文检索 (FTS)	Whoosh / SQLite FTS5	倒排索引 (Inverted Index)：类似书后的索引表，记录单词出现在哪一页。	关键词匹配极其精准，极其轻量（纯 Python 或 单文件数据库）。	“关键词搜索工具”：用于 Agent 寻找“母线”、“110kV”等专有名词。
现代高性能 FTS	Tantivy	Rust 编写的倒排索引：Lucene 的 Rust 极致性能实现版。	比 Whoosh 快 10 倍以上，常用于处理海量文档。	“工业级引擎”：如果你的安规手册有几万页，或需要极速响应，用它。
向量数据库 (Vector)	LanceDB	向量嵌入 (Embeddings)：将文字转为坐标，计算距离。	擅长“语义模糊匹配”，即用户描述和原文词汇不一致时。	“语义理解工具”：用于 Agent 寻找“故障描述”这种难以用关键词概括的内容。
2. 它们如何协同工作？
在类似 Claude Code 的 MCP Server 实现中，我们通常不会只选一个，而是组合使用，这被称为 “混合搜索 (Hybrid Search)”：

SQLite FTS5 (负责“点”): 当 Agent 搜索“220kV 开关故障”时，FTS5 能瞬间定位到包含这些精确专有名词的章节，误差几乎为零。

LanceDB (负责“面”): 当用户问“如果设备冒烟了该怎么办？”，而安规里写的是“电气火灾处置”或“异常发热”，此时关键词搜不到。Agent 会调用 LanceDB，根据语义找到相关的处置规则。

Tantivy (备选): 如果你希望 MCP Server 足够快，且不依赖 SQLite，Tantivy 是目前开源界最时髦的选择，因为它能把索引存在一个二进制文件夹里，性能极强且不占内存。

3. 在安规场景下的抉择建议
对于你的**“安规检索”**需求，我给出的技术选型建议如下：

方案 A：极简起步 (推荐)
工具：SQLite FTS5

理由：安规文档虽然多，但对于计算机来说其实并不大（通常在几十 MB 到几百 MB）。SQLite FTS5 是内置在 Python 环境里的，不需要额外安装复杂的库。它能让你迅速实现 search_in_chapter 功能。

方案 B：追求“语义”理解 (高阶)
工具：LanceDB

理由：如果你发现用户总是记不清安规里的术语，用 LanceDB 配合本地的小型 Embedding 模型（如 BGE-m3），能大幅提升 Agent 找表的成功率。

4. 总结它们在 MCP Server 中的逻辑链路
用户提问 ->

Agent 调用工具 ->

MCP Server 接收请求 ->

如果是搜特定词：调用 SQLite FTS5/Tantivy。

如果是搜某种意思：调用 LanceDB。

返回结果（包含 Page, Chapter, Context）。

一句话总结： Whoosh/SQLite 是基础款的“关键词表”，Tantivy 是它的专业竞速版，而 LanceDB 是能听懂人话的“意图匹配器”。

你想看看如何用几行 Python 代码在 MCP Server 里启动一个 SQLite FTS5 索引吗？这通常是构建此类系统的第一步。

问题是搜索结果如何能返回Page, Chapter这些

要让搜索结果返回 Page（页码） 和 Chapter（章节），关键在于**“索引前的文档打标（Tagging）”**。

在 MCP Server 中，你不能把文档当作一个长字符串存入，而必须将其视为一系列带有属性的数据记录。无论你使用 SQLite FTS5 还是 Tantivy，核心逻辑是一致的。

以下是实现这一目标的三步流程：

1. 数据解析：构建“结构化感知”的记录
当你使用 Docling 解析安规 PDF 时，它会产生一个层级对象。你需要将这个对象打碎，存入搜索引擎。

每一条记录（Document）的结构应该如下：

JSON
{
  "content": "表格或正文的具体文字内容...",
  "page_num": 85,
  "chapter": "第六章 事故处理",
  "section": "第三节 变压器异常",
  "id": "2024_ag_p85_s3"
}
2. 在 SQLite FTS5 中实现返回 Page 和 Chapter
在 SQLite 中，你需要建立一个包含元数据列的虚拟表。

核心 SQL 实现：

SQL
-- 1. 创建虚拟表，content 用于搜索，其他列用于存储元数据
CREATE VIRTUAL TABLE safety_rules USING fts5(
    content, 
    page_num UNINDEXED, -- UNINDEXED 表示该列不参与搜索，仅用于存储
    chapter UNINDEXED,
    section UNINDEXED
);

-- 2. 搜索并提取元数据
SELECT 
    page_num, 
    chapter, 
    section, 
    snippet(safety_rules, 0, '<b>', '</b>', '...', 10) as highlight -- 返回匹配片段
FROM safety_rules 
WHERE content MATCH '母线失压' 
ORDER BY rank;
3. MCP Server 内部的逻辑封装
当 Agent 调用 search_text("母线失压") 时，MCP Server 的 Python 代码需要执行以下操作：

执行检索：从数据库中拿到 page_num 和 chapter。

构建锚点：不要只返回文字，要返回一个带有坐标的引用对象。

返回给 Agent：

Plaintext
找到 2 处匹配：
1. [第六章 P85] "...若110kV母线失压，应立即..."
2. [第十章 P142] "...母线失压时的保护动作说明..."
4. 为什么这种设计能像 Claude Code？
Claude Code 之所以能定位到具体文件的某一行，是因为它的索引里存了 file_path 和 line_number。 在你的场景下：

Chapter = 对应代码的 file_path（提供逻辑归属）。

Page = 对应代码的 line_number（提供空间定位）。

进阶：如何处理“跨页表格”的定位？
如果一个搜索词出现在跨页表格的第二页（没有表头的那一页），由于你的每一条记录都带有 chapter 和 page_num 标签，Agent 拿到结果后会发现：

结果在 P86。

Agent 发现这是表格续表。

Agent 自动调用 read_pages(85, 86)，从而把表头和数据拼接起来。

总结方案：实现代码的核心片段 (Python)
Python
import sqlite3

def search_rules(query):
    db = sqlite3.connect("safety_manual.db")
    cursor = db.cursor()
    # 搜索并返回结果及其坐标
    results = cursor.execute("""
        SELECT chapter, page_num, snippet(safety_rules, 0, '[', ']', '...', 20) 
        FROM safety_rules WHERE content MATCH ?
    """, (query,)).fetchall()
    
    # 格式化给 Agent，让它知道去哪翻页
    formatted_results = []
    for chapter, page, text in results:
        formatted_results.append(f"Location: {chapter} (Page {page})\nSnippet: {text}")
    
    return "\n\n".join(formatted_results)
这种通过元数据字段强制关联“物理坐标”的方式，能解决你对定位的担忧吗？ 如果需要，我可以展示如何利用 Docling 在解析时自动提取这些 Chapter 和 Page 的逻辑。